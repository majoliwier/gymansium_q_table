{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-24T07:47:32.014240Z",
     "start_time": "2025-04-24T07:47:29.116296Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# parameters",
   "id": "c9f3160c45adf8f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T07:47:32.049167Z",
     "start_time": "2025-04-24T07:47:32.016149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")\n",
    "\n",
    "discount_factor = 0.9\n",
    "learning_rate = 0.9\n",
    "training = False\n",
    "episodes = 10000\n",
    "\n",
    "if training:\n",
    "    q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "else:\n",
    "    f = open('q_table.pkl', 'rb')\n",
    "    q_table = pickle.load(f)\n",
    "    f.close()"
   ],
   "id": "7d927e00a2e22228",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# training q table",
   "id": "944606dfd8cfb577"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T07:47:32.066459Z",
     "start_time": "2025-04-24T07:47:32.049827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if training:\n",
    "    episode_rewards = []\n",
    "    for episode in range(episodes): \n",
    "        state, _ = env.reset()\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        total_reward = 0\n",
    "        while (not terminated and not truncated):\n",
    "            action = np.argmax(q_table[state,:])\n",
    "            \n",
    "            new_state, reward, terminated, truncated, info = env.step(action)\n",
    "            total_reward += reward  \n",
    "            \n",
    "            # bellman equation\n",
    "            q_table[state, action] = (\n",
    "                (1 - learning_rate) * q_table[state, action] +\n",
    "                learning_rate * (reward + discount_factor * np.max(q_table[new_state, :])))\n",
    "            \n",
    "            state = new_state\n",
    "        episode_rewards.append(total_reward)\n",
    "    env.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(episode_rewards)\n",
    "    plt.xlabel('episode')\n",
    "    plt.ylabel('total reward')\n",
    "    plt.title('learning rate')\n",
    "    plt.savefig('learning_curve.png')\n",
    "    \n",
    "    window_size = 100\n",
    "    averaged_rewards = [\n",
    "    np.mean(episode_rewards[i:i + window_size])\n",
    "    for i in range(0, len(episode_rewards), window_size)\n",
    "    ]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(averaged_rewards)\n",
    "    plt.xlabel('every 100th episode')\n",
    "    plt.ylabel('total reward')\n",
    "    plt.title('learning rate')\n",
    "    plt.savefig('learning_curve_100th.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "    f = open('q_table.pkl', 'wb')\n",
    "    pickle.dump(q_table, f)\n",
    "    f.close()"
   ],
   "id": "23891553cdae24a8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T07:47:32.089171Z",
     "start_time": "2025-04-24T07:47:32.066763Z"
    }
   },
   "cell_type": "code",
   "source": "print(q_table)",
   "id": "41840ba5a3182430",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.          0.        ]\n",
      " [-5.80760022 -5.720702   -5.98263332 -5.720702    1.62261467 -9.        ]\n",
      " [-4.31453434 -4.32130748 -4.26570876 -4.32130748  7.7147     -9.        ]\n",
      " ...\n",
      " [-3.1425039  -3.19779549 -3.1425039  -3.0016359  -9.         -9.        ]\n",
      " [-4.83238981 -0.05705194 -4.83238981 -5.08600151 -9.         -9.        ]\n",
      " [-1.719      -1.719      -1.719      13.59       -9.         -9.        ]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# game with learned q table",
   "id": "4b98b9d7c242b046"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T07:48:35.988108Z",
     "start_time": "2025-04-24T07:48:32.435465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state, _ = env.reset()\n",
    "terminated = False\n",
    "truncated = False\n",
    "rewards = 0\n",
    "while (not terminated and not truncated):\n",
    "    action = np.argmax(q_table[state,:])\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    rewards+= reward\n",
    "    \n",
    "    cv2.imshow('Bolciarz the game', cv2.cvtColor(env.render(), cv2.COLOR_RGB2BGR))\n",
    "    cv2.waitKey(250)\n",
    "    if cv2.getWindowProperty('Bolciarz the game', cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"total reward: {rewards}\")"
   ],
   "id": "b434f97bdea12778",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward: 8\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "946b0b711a5350d3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
